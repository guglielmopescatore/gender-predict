All seeds set to 42
Using BCEWithLogitsLoss with pos_weight=1.1
Using device: cuda
Running Round 2 training...
Loading data from training_dataset.csv...
Loaded 5271571 records
Train set: 4217256 records
Validation set: 527157 records
Test set: 527158 records

Distribuzione di genere:
  Train:
    M: 2628358 (62.32%)
    W: 1588898 (37.68%)
  Validation:
    M: 328545 (62.32%)
    W: 198612 (37.68%)
  Test:
    M: 328545 (62.32%)
    W: 198613 (37.68%)
Using enhanced model with 2 layers, hidden size 80, dual_input=False
Starting training for Round 2 with 15 epochs...
Using freezing for first 4 epochs
Epoch 1/15: Freezing embedding and first LSTM layer
Epoch 1/15 | Time: 142.66s
Train Loss: 0.5276 | Train Acc: 0.7599
Val Loss: 0.4596 | Val Acc: 0.8081
Val Precision: 0.7877 | Val Recall: 0.6718 | Val F1: 0.7252
------------------------------------------------------------
Epoch 2/15: Freezing embedding and first LSTM layer
Epoch 2/15 | Time: 142.34s
Train Loss: 0.5007 | Train Acc: 0.7750
Val Loss: 0.4431 | Val Acc: 0.8158
Val Precision: 0.7725 | Val Recall: 0.7245 | Val F1: 0.7477
------------------------------------------------------------
Epoch 3/15: Freezing embedding and first LSTM layer
Epoch 3/15 | Time: 141.22s
Train Loss: 0.4849 | Train Acc: 0.7827
Val Loss: 0.4337 | Val Acc: 0.8195
Val Precision: 0.7839 | Val Recall: 0.7192 | Val F1: 0.7502
------------------------------------------------------------
Epoch 4/15: Freezing embedding and first LSTM layer
Epoch 4/15 | Time: 141.01s
Train Loss: 0.4717 | Train Acc: 0.7901
Val Loss: 0.4305 | Val Acc: 0.8274
Val Precision: 0.7913 | Val Recall: 0.7362 | Val F1: 0.7627
------------------------------------------------------------
Epoch 5/15: Unfreezing all layers
Epoch 5/15 | Time: 165.49s
Train Loss: 0.3051 | Train Acc: 0.8821
Val Loss: 0.2576 | Val Acc: 0.9048
Val Precision: 0.8506 | Val Recall: 0.9066 | Val F1: 0.8777

Bias analysis on validation set:

--- Analisi del Bias di Genere ---
Matrice di Confusione:
[[296919  31626]
 [ 18541 180071]]

Accuratezza Globale: 0.905

Metriche per Genere:
  Maschi (M):
    Precisione: 0.941 (quanti dei predetti maschi sono effettivamente maschi)
    Recall: 0.904 (quanti maschi reali sono stati identificati correttamente)
    F1-Score: 0.922
  Femmine (W):
    Precisione: 0.851 (quante delle predette femmine sono effettivamente femmine)
    Recall: 0.907 (quante femmine reali sono state identificate correttamente)
    F1-Score: 0.878

Analisi del Bias:
  Errore M→W: 31626 nomi maschili classificati come femminili (9.6% dei maschi)
  Errore W→M: 18541 nomi femminili classificati come maschili (9.3% delle femmine)
  Bias Ratio (M→W : W→M): 1.031
  → Il modello mostra un bias equilibrato tra i generi
------------------------------------------------------------
Epoch 6/15 | Time: 163.34s
Train Loss: 0.2590 | Train Acc: 0.9046
Val Loss: 0.2482 | Val Acc: 0.9096
Val Precision: 0.8597 | Val Recall: 0.9083 | Val F1: 0.8833
------------------------------------------------------------
Epoch 7/15 | Time: 164.60s
Train Loss: 0.2514 | Train Acc: 0.9082
Val Loss: 0.2467 | Val Acc: 0.9104
Val Precision: 0.8564 | Val Recall: 0.9156 | Val F1: 0.8850
------------------------------------------------------------
Epoch 8/15 | Time: 162.38s
Train Loss: 0.2476 | Train Acc: 0.9096
Val Loss: 0.2441 | Val Acc: 0.9118
Val Precision: 0.8645 | Val Recall: 0.9082 | Val F1: 0.8858
------------------------------------------------------------
Epoch 9/15 | Time: 157.47s
Train Loss: 0.2451 | Train Acc: 0.9106
Val Loss: 0.2426 | Val Acc: 0.9123
Val Precision: 0.8599 | Val Recall: 0.9165 | Val F1: 0.8873
------------------------------------------------------------
Epoch 10/15 | Time: 155.79s
Train Loss: 0.2435 | Train Acc: 0.9113
Val Loss: 0.2418 | Val Acc: 0.9124
Val Precision: 0.8604 | Val Recall: 0.9163 | Val F1: 0.8875

Bias analysis on validation set:

--- Analisi del Bias di Genere ---
Matrice di Confusione:
[[299005  29540]
 [ 16617 181995]]

Accuratezza Globale: 0.912

Metriche per Genere:
  Maschi (M):
    Precisione: 0.947 (quanti dei predetti maschi sono effettivamente maschi)
    Recall: 0.910 (quanti maschi reali sono stati identificati correttamente)
    F1-Score: 0.928
  Femmine (W):
    Precisione: 0.860 (quante delle predette femmine sono effettivamente femmine)
    Recall: 0.916 (quante femmine reali sono state identificate correttamente)
    F1-Score: 0.887

Analisi del Bias:
  Errore M→W: 29540 nomi maschili classificati come femminili (9.0% dei maschi)
  Errore W→M: 16617 nomi femminili classificati come maschili (8.4% delle femmine)
  Bias Ratio (M→W : W→M): 1.075
  → Il modello mostra un bias equilibrato tra i generi
------------------------------------------------------------
Epoch 11/15 | Time: 155.84s
Train Loss: 0.2424 | Train Acc: 0.9118
Val Loss: 0.2412 | Val Acc: 0.9125
Val Precision: 0.8583 | Val Recall: 0.9195 | Val F1: 0.8878
------------------------------------------------------------
Epoch 12/15 | Time: 156.29s
Train Loss: 0.2414 | Train Acc: 0.9122
Val Loss: 0.2415 | Val Acc: 0.9136
Val Precision: 0.8679 | Val Recall: 0.9090 | Val F1: 0.8880
------------------------------------------------------------
Early stopping triggered after epoch 12
Model saved to ./models/round2_best.pth
Evaluating on test set...
Test Accuracy: 0.9144
Test Precision: 0.8687
Test Recall: 0.9103
Test F1: 0.8890

Detailed bias analysis on test set:

--- Analisi del Bias di Genere ---
Matrice di Confusione:
[[301215  27330]
 [ 17806 180807]]

Accuratezza Globale: 0.914

Metriche per Genere:
  Maschi (M):
    Precisione: 0.944 (quanti dei predetti maschi sono effettivamente maschi)
    Recall: 0.917 (quanti maschi reali sono stati identificati correttamente)
    F1-Score: 0.930
  Femmine (W):
    Precisione: 0.869 (quante delle predette femmine sono effettivamente femmine)
    Recall: 0.910 (quante femmine reali sono state identificate correttamente)
    F1-Score: 0.889

Analisi del Bias:
  Errore M→W: 27330 nomi maschili classificati come femminili (8.3% dei maschi)
  Errore W→M: 17806 nomi femminili classificati come maschili (9.0% delle femmine)
  Bias Ratio (M→W : W→M): 0.928
  → Il modello mostra un bias equilibrato tra i generi
Round 2 completed successfully!
